############
# Parameters
############

######
# Data
######
# fashion_mnist, cifar10, cifar100
# dataset: "blobs"
# dataset: "mnist"
dataset: "fashion_mnist"
# dataset: "cifar10"
# dataset: "cifar100"
# Use subset of dataset: float (0, 1]
subset_ratio: 0.1

#########
# Network
#########
n_dims_hidden: 64
n_layers_hidden: 6

###########
# Evolution
###########
# Network topology search with genetic optimization.
n_generations: 100000
n_agents: 2  # n_organisms
# Not used parameters
local_mutation_rate: -1
global_mutation_rate: -1
increase_epochs_every_n: -1

##########
# Training
##########
# Parameter optimization with gradient descent.
n_epochs: 1
step_size: 999999999
learning_rate: 1.0e-3
gamma: 1.0
weight_decay: 1.0e-4
batch_size: 32
dropout_rate: 0.1

###############
# Miscellaneous
###############
random_seed: 69
n_workers: 1
stats_every_n_epochs: 1

#################
# Hyperparameters
#################
# todo: add these to extra file hparams.yml?
hparams:

  weight_decay:
    mutate: true
    type: "float"
    scale: "log"
    step_size: 0.
    val_init: 4
    val_min: 2
    val_max: 128

  n_dims_hidden:
    mutate: true
    type: "int"
    scale: "linear"
    step_size: 1
    val_init: 4
    val_min: 2
    val_max: 128

  n_layers_hidden:
    mutate: true
    type: "int"
    scale: "linear"
    step_size: 1
    val_init: 4
    val_min: 1
    val_max: 8